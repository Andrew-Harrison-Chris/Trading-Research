{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import indicators\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "(4780, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>33.601013</td>\n",
       "      <td>33.601013</td>\n",
       "      <td>33.601013</td>\n",
       "      <td>33.601013</td>\n",
       "      <td>12.179194</td>\n",
       "      <td>0</td>\n",
       "      <td>2001-05-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>33.601013</td>\n",
       "      <td>33.601013</td>\n",
       "      <td>33.601013</td>\n",
       "      <td>33.601013</td>\n",
       "      <td>12.179194</td>\n",
       "      <td>0</td>\n",
       "      <td>2001-05-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>33.601013</td>\n",
       "      <td>33.601013</td>\n",
       "      <td>33.601013</td>\n",
       "      <td>33.601013</td>\n",
       "      <td>12.179194</td>\n",
       "      <td>0</td>\n",
       "      <td>2001-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>33.601013</td>\n",
       "      <td>33.601013</td>\n",
       "      <td>33.601013</td>\n",
       "      <td>33.601013</td>\n",
       "      <td>12.179194</td>\n",
       "      <td>0</td>\n",
       "      <td>2001-05-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>33.601013</td>\n",
       "      <td>33.601013</td>\n",
       "      <td>33.601013</td>\n",
       "      <td>33.601013</td>\n",
       "      <td>12.179194</td>\n",
       "      <td>0</td>\n",
       "      <td>2001-05-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Open       High        Low      Close  Adj Close  Volume       Date\n",
       "0  33.601013  33.601013  33.601013  33.601013  12.179194       0 2001-05-16\n",
       "1  33.601013  33.601013  33.601013  33.601013  12.179194       0 2001-05-17\n",
       "2  33.601013  33.601013  33.601013  33.601013  12.179194       0 2001-05-18\n",
       "3  33.601013  33.601013  33.601013  33.601013  12.179194       0 2001-05-21\n",
       "4  33.601013  33.601013  33.601013  33.601013  12.179194       0 2001-05-22"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in stock data \n",
    "data = yfinance.download('IDT')\n",
    "print(data.shape)\n",
    "data['Date'] = data.index\n",
    "data.reset_index(drop=True,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HarrisonHoffman/Desktop/chris-harrison-ml/Trading-Research/indicators.py:552: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  dc = max(df['High'].ix[i:i + n - 1]) - min(df['Low'].ix[i:i + n - 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4274, 174)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Date</th>\n",
       "      <th>Acc/Dist_ROC_5</th>\n",
       "      <th>Acc/Dist_ROC_7</th>\n",
       "      <th>Acc/Dist_ROC_14</th>\n",
       "      <th>...</th>\n",
       "      <th>Trix_21</th>\n",
       "      <th>Trix_50</th>\n",
       "      <th>Trix_100</th>\n",
       "      <th>Ultimate_Osc</th>\n",
       "      <th>Vortex_5</th>\n",
       "      <th>Vortex_7</th>\n",
       "      <th>Vortex_14</th>\n",
       "      <th>Vortex_21</th>\n",
       "      <th>Vortex_50</th>\n",
       "      <th>Vortex_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4774</td>\n",
       "      <td>5.60</td>\n",
       "      <td>5.90</td>\n",
       "      <td>5.60</td>\n",
       "      <td>5.78</td>\n",
       "      <td>5.78</td>\n",
       "      <td>83900</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>-1.582808</td>\n",
       "      <td>-0.114429</td>\n",
       "      <td>-4.784986</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005210</td>\n",
       "      <td>-0.003299</td>\n",
       "      <td>-0.001223</td>\n",
       "      <td>3.431815</td>\n",
       "      <td>0.517647</td>\n",
       "      <td>0.107623</td>\n",
       "      <td>0.093960</td>\n",
       "      <td>0.075269</td>\n",
       "      <td>-0.113933</td>\n",
       "      <td>-0.005562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4775</td>\n",
       "      <td>5.70</td>\n",
       "      <td>5.92</td>\n",
       "      <td>5.57</td>\n",
       "      <td>5.84</td>\n",
       "      <td>5.84</td>\n",
       "      <td>69400</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>-3.051397</td>\n",
       "      <td>-0.600908</td>\n",
       "      <td>-2.034199</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004897</td>\n",
       "      <td>-0.003324</td>\n",
       "      <td>-0.001245</td>\n",
       "      <td>3.668448</td>\n",
       "      <td>0.530726</td>\n",
       "      <td>0.328889</td>\n",
       "      <td>0.190157</td>\n",
       "      <td>0.042292</td>\n",
       "      <td>-0.085075</td>\n",
       "      <td>-0.011127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4776</td>\n",
       "      <td>5.90</td>\n",
       "      <td>5.97</td>\n",
       "      <td>5.69</td>\n",
       "      <td>5.82</td>\n",
       "      <td>5.82</td>\n",
       "      <td>57400</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>-0.479238</td>\n",
       "      <td>-0.857602</td>\n",
       "      <td>-1.170362</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004560</td>\n",
       "      <td>-0.003344</td>\n",
       "      <td>-0.001267</td>\n",
       "      <td>3.510134</td>\n",
       "      <td>0.472050</td>\n",
       "      <td>0.446352</td>\n",
       "      <td>0.182819</td>\n",
       "      <td>0.145228</td>\n",
       "      <td>-0.112015</td>\n",
       "      <td>-0.021058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4777</td>\n",
       "      <td>5.83</td>\n",
       "      <td>5.94</td>\n",
       "      <td>5.49</td>\n",
       "      <td>5.60</td>\n",
       "      <td>5.60</td>\n",
       "      <td>73700</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>-0.108693</td>\n",
       "      <td>1.051101</td>\n",
       "      <td>-2.575376</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004237</td>\n",
       "      <td>-0.003360</td>\n",
       "      <td>-0.001289</td>\n",
       "      <td>3.323440</td>\n",
       "      <td>0.320652</td>\n",
       "      <td>0.353175</td>\n",
       "      <td>0.122271</td>\n",
       "      <td>0.079387</td>\n",
       "      <td>-0.135344</td>\n",
       "      <td>-0.036156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4778</td>\n",
       "      <td>5.47</td>\n",
       "      <td>5.49</td>\n",
       "      <td>5.02</td>\n",
       "      <td>5.42</td>\n",
       "      <td>5.42</td>\n",
       "      <td>159900</td>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>5.690684</td>\n",
       "      <td>-15.260365</td>\n",
       "      <td>1.878733</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003952</td>\n",
       "      <td>-0.003374</td>\n",
       "      <td>-0.001310</td>\n",
       "      <td>3.628473</td>\n",
       "      <td>-0.252381</td>\n",
       "      <td>-0.147727</td>\n",
       "      <td>-0.078313</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>-0.161786</td>\n",
       "      <td>-0.066759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Open  High   Low  Close  Adj Close  Volume       Date  Acc/Dist_ROC_5  \\\n",
       "4774  5.60  5.90  5.60   5.78       5.78   83900 2020-05-08       -1.582808   \n",
       "4775  5.70  5.92  5.57   5.84       5.84   69400 2020-05-11       -3.051397   \n",
       "4776  5.90  5.97  5.69   5.82       5.82   57400 2020-05-12       -0.479238   \n",
       "4777  5.83  5.94  5.49   5.60       5.60   73700 2020-05-13       -0.108693   \n",
       "4778  5.47  5.49  5.02   5.42       5.42  159900 2020-05-14        5.690684   \n",
       "\n",
       "      Acc/Dist_ROC_7  Acc/Dist_ROC_14  ...   Trix_21   Trix_50  Trix_100  \\\n",
       "4774       -0.114429        -4.784986  ... -0.005210 -0.003299 -0.001223   \n",
       "4775       -0.600908        -2.034199  ... -0.004897 -0.003324 -0.001245   \n",
       "4776       -0.857602        -1.170362  ... -0.004560 -0.003344 -0.001267   \n",
       "4777        1.051101        -2.575376  ... -0.004237 -0.003360 -0.001289   \n",
       "4778      -15.260365         1.878733  ... -0.003952 -0.003374 -0.001310   \n",
       "\n",
       "      Ultimate_Osc  Vortex_5  Vortex_7  Vortex_14  Vortex_21  Vortex_50  \\\n",
       "4774      3.431815  0.517647  0.107623   0.093960   0.075269  -0.113933   \n",
       "4775      3.668448  0.530726  0.328889   0.190157   0.042292  -0.085075   \n",
       "4776      3.510134  0.472050  0.446352   0.182819   0.145228  -0.112015   \n",
       "4777      3.323440  0.320652  0.353175   0.122271   0.079387  -0.135344   \n",
       "4778      3.628473 -0.252381 -0.147727  -0.078313  -0.008231  -0.161786   \n",
       "\n",
       "      Vortex_100  \n",
       "4774   -0.005562  \n",
       "4775   -0.011127  \n",
       "4776   -0.021058  \n",
       "4777   -0.036156  \n",
       "4778   -0.066759  \n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = indicators.accumulation_distribution(data,5)\n",
    "data = indicators.accumulation_distribution(data,7)\n",
    "data = indicators.accumulation_distribution(data,14)\n",
    "data = indicators.accumulation_distribution(data,21)\n",
    "data = indicators.accumulation_distribution(data,50)\n",
    "data = indicators.accumulation_distribution(data,100)\n",
    "\n",
    "data = indicators.average_true_range(data,5)\n",
    "data = indicators.average_true_range(data,7)\n",
    "data = indicators.average_true_range(data,14)\n",
    "data = indicators.average_true_range(data,21)\n",
    "data = indicators.average_true_range(data,50)\n",
    "data = indicators.average_true_range(data,100)\n",
    "\n",
    "data = indicators.bollinger_bands(data,5)\n",
    "data = indicators.bollinger_bands(data,7)\n",
    "data = indicators.bollinger_bands(data,14)\n",
    "data = indicators.bollinger_bands(data,21)\n",
    "data = indicators.bollinger_bands(data,50)\n",
    "data = indicators.bollinger_bands(data,100)\n",
    "\n",
    "data = indicators.chaikin_oscillator(data)\n",
    "\n",
    "data = indicators.commodity_channel_index(data,5)\n",
    "data = indicators.commodity_channel_index(data,7)\n",
    "data = indicators.commodity_channel_index(data,14)\n",
    "data = indicators.commodity_channel_index(data,21)\n",
    "data = indicators.commodity_channel_index(data,50)\n",
    "data = indicators.commodity_channel_index(data,100)\n",
    "\n",
    "data = indicators.coppock_curve(data,5)\n",
    "data = indicators.coppock_curve(data,7)\n",
    "data = indicators.coppock_curve(data,14)\n",
    "data = indicators.coppock_curve(data,21)\n",
    "data = indicators.coppock_curve(data,50)\n",
    "data = indicators.coppock_curve(data,100)\n",
    "\n",
    "data = indicators.donchian_channel(data,5)\n",
    "data = indicators.donchian_channel(data,7)\n",
    "data = indicators.donchian_channel(data,14)\n",
    "data = indicators.donchian_channel(data,21)\n",
    "data = indicators.donchian_channel(data,50)\n",
    "data = indicators.donchian_channel(data,100)\n",
    "\n",
    "data = indicators.ease_of_movement(data,5)\n",
    "data = indicators.ease_of_movement(data,7)\n",
    "data = indicators.ease_of_movement(data,14)\n",
    "data = indicators.ease_of_movement(data,21)\n",
    "data = indicators.ease_of_movement(data,50)\n",
    "data = indicators.ease_of_movement(data,100)\n",
    "\n",
    "data = indicators.exponential_moving_average(data,5)\n",
    "data = indicators.exponential_moving_average(data,7)\n",
    "data = indicators.exponential_moving_average(data,14)\n",
    "data = indicators.exponential_moving_average(data,21)\n",
    "data = indicators.exponential_moving_average(data,50)\n",
    "data = indicators.exponential_moving_average(data,100)\n",
    "\n",
    "data = indicators.force_index(data,5)\n",
    "data = indicators.force_index(data,7)\n",
    "data = indicators.force_index(data,14)\n",
    "data = indicators.force_index(data,21)\n",
    "data = indicators.force_index(data,50)\n",
    "data = indicators.force_index(data,100)\n",
    "\n",
    "data = indicators.keltner_channel(data,5)\n",
    "data = indicators.keltner_channel(data,7)\n",
    "data = indicators.keltner_channel(data,14)\n",
    "data = indicators.keltner_channel(data,21)\n",
    "data = indicators.keltner_channel(data,50)\n",
    "data = indicators.keltner_channel(data,100)\n",
    "\n",
    "data = indicators.macd(data,5,5)\n",
    "data = indicators.macd(data,7,7)\n",
    "data = indicators.macd(data,14,14)\n",
    "data = indicators.macd(data,21,21)\n",
    "data = indicators.macd(data,50,50)\n",
    "data = indicators.macd(data,100,100)\n",
    "\n",
    "data = indicators.mass_index(data)\n",
    "\n",
    "data = indicators.momentum(data,5)\n",
    "data = indicators.momentum(data,7)\n",
    "data = indicators.momentum(data,14)\n",
    "data = indicators.momentum(data,21)\n",
    "data = indicators.momentum(data,50)\n",
    "data = indicators.momentum(data,100)\n",
    "\n",
    "data = indicators.money_flow_index(data,5)\n",
    "data = indicators.money_flow_index(data,7)\n",
    "data = indicators.money_flow_index(data,14)\n",
    "data = indicators.money_flow_index(data,21)\n",
    "data = indicators.money_flow_index(data,50)\n",
    "data = indicators.money_flow_index(data,100)\n",
    "\n",
    "data = indicators.moving_average(data,5)\n",
    "data = indicators.moving_average(data,7)\n",
    "data = indicators.moving_average(data,14)\n",
    "data = indicators.moving_average(data,21)\n",
    "data = indicators.moving_average(data,50)\n",
    "data = indicators.moving_average(data,100)\n",
    "\n",
    "data = indicators.on_balance_volume(data,5)\n",
    "data = indicators.on_balance_volume(data,7)\n",
    "data = indicators.on_balance_volume(data,14)\n",
    "data = indicators.on_balance_volume(data,21)\n",
    "data = indicators.on_balance_volume(data,50)\n",
    "data = indicators.on_balance_volume(data,100)\n",
    "\n",
    "data = indicators.ppsr(data)\n",
    "\n",
    "data = indicators.rate_of_change(data,5)\n",
    "data = indicators.rate_of_change(data,7)\n",
    "data = indicators.rate_of_change(data,14)\n",
    "data = indicators.rate_of_change(data,21)\n",
    "data = indicators.rate_of_change(data,50)\n",
    "data = indicators.rate_of_change(data,100)\n",
    "\n",
    "data = indicators.relative_strength_index(data,5)\n",
    "data = indicators.relative_strength_index(data,7)\n",
    "data = indicators.relative_strength_index(data,14)\n",
    "data = indicators.relative_strength_index(data,21)\n",
    "data = indicators.relative_strength_index(data,50)\n",
    "data = indicators.relative_strength_index(data,100)\n",
    "\n",
    "data = indicators.standard_deviation(data,5)\n",
    "data = indicators.standard_deviation(data,7)\n",
    "data = indicators.standard_deviation(data,14)\n",
    "data = indicators.standard_deviation(data,21)\n",
    "data = indicators.standard_deviation(data,50)\n",
    "data = indicators.standard_deviation(data,100)\n",
    "\n",
    "data = indicators.stochastic_oscillator_d(data,5)\n",
    "data = indicators.stochastic_oscillator_d(data,7)\n",
    "data = indicators.stochastic_oscillator_d(data,14)\n",
    "data = indicators.stochastic_oscillator_d(data,21)\n",
    "data = indicators.stochastic_oscillator_d(data,50)\n",
    "data = indicators.stochastic_oscillator_d(data,100)\n",
    "\n",
    "data = indicators.stochastic_oscillator_k(data)\n",
    "\n",
    "data = indicators.trix(data,5)\n",
    "data = indicators.trix(data,7)\n",
    "data = indicators.trix(data,14)\n",
    "data = indicators.trix(data,21)\n",
    "data = indicators.trix(data,50)\n",
    "data = indicators.trix(data,100)\n",
    "\n",
    "data = indicators.ultimate_oscillator(data)\n",
    "\n",
    "data = indicators.vortex_indicator(data,5)\n",
    "data = indicators.vortex_indicator(data,7)\n",
    "data = indicators.vortex_indicator(data,14)\n",
    "data = indicators.vortex_indicator(data,21)\n",
    "data = indicators.vortex_indicator(data,50)\n",
    "data = indicators.vortex_indicator(data,100)\n",
    "\n",
    "data = data.replace([np.inf, -np.inf], np.nan)\n",
    "data = data.dropna()\n",
    "print(data.shape)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Date</th>\n",
       "      <th>Acc/Dist_ROC_5</th>\n",
       "      <th>Acc/Dist_ROC_7</th>\n",
       "      <th>Acc/Dist_ROC_14</th>\n",
       "      <th>...</th>\n",
       "      <th>Vortex_5</th>\n",
       "      <th>Vortex_7</th>\n",
       "      <th>Vortex_14</th>\n",
       "      <th>Vortex_21</th>\n",
       "      <th>Vortex_50</th>\n",
       "      <th>Vortex_100</th>\n",
       "      <th>Close3</th>\n",
       "      <th>Direction3</th>\n",
       "      <th>Close5</th>\n",
       "      <th>Direction5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4761</td>\n",
       "      <td>5.37</td>\n",
       "      <td>5.37</td>\n",
       "      <td>5.19</td>\n",
       "      <td>5.27</td>\n",
       "      <td>5.27</td>\n",
       "      <td>39900</td>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>-1.072744</td>\n",
       "      <td>-1.475947</td>\n",
       "      <td>-0.893971</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>-0.188811</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>-0.041152</td>\n",
       "      <td>-0.135502</td>\n",
       "      <td>-0.061700</td>\n",
       "      <td>5.49</td>\n",
       "      <td>True</td>\n",
       "      <td>5.50</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4762</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.48</td>\n",
       "      <td>5.27</td>\n",
       "      <td>5.30</td>\n",
       "      <td>5.30</td>\n",
       "      <td>51000</td>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>-369815.888601</td>\n",
       "      <td>-0.388044</td>\n",
       "      <td>-1.712670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151163</td>\n",
       "      <td>0.081784</td>\n",
       "      <td>0.034711</td>\n",
       "      <td>0.058700</td>\n",
       "      <td>-0.136657</td>\n",
       "      <td>-0.051353</td>\n",
       "      <td>5.73</td>\n",
       "      <td>True</td>\n",
       "      <td>5.56</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4763</td>\n",
       "      <td>5.30</td>\n",
       "      <td>5.60</td>\n",
       "      <td>5.19</td>\n",
       "      <td>5.45</td>\n",
       "      <td>5.45</td>\n",
       "      <td>89700</td>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>-14.262400</td>\n",
       "      <td>-0.605121</td>\n",
       "      <td>-1.486214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131429</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.016639</td>\n",
       "      <td>-0.002132</td>\n",
       "      <td>-0.127584</td>\n",
       "      <td>-0.051791</td>\n",
       "      <td>5.50</td>\n",
       "      <td>True</td>\n",
       "      <td>5.40</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4764</td>\n",
       "      <td>5.45</td>\n",
       "      <td>5.50</td>\n",
       "      <td>5.32</td>\n",
       "      <td>5.49</td>\n",
       "      <td>5.49</td>\n",
       "      <td>26900</td>\n",
       "      <td>2020-04-24</td>\n",
       "      <td>0.450915</td>\n",
       "      <td>242739.307573</td>\n",
       "      <td>-0.771792</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.040636</td>\n",
       "      <td>-0.009815</td>\n",
       "      <td>-0.132882</td>\n",
       "      <td>-0.050960</td>\n",
       "      <td>5.56</td>\n",
       "      <td>True</td>\n",
       "      <td>5.41</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4765</td>\n",
       "      <td>5.55</td>\n",
       "      <td>5.80</td>\n",
       "      <td>5.54</td>\n",
       "      <td>5.73</td>\n",
       "      <td>5.73</td>\n",
       "      <td>84500</td>\n",
       "      <td>2020-04-27</td>\n",
       "      <td>-9.796976</td>\n",
       "      <td>-22.492446</td>\n",
       "      <td>-1.454504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178082</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.104673</td>\n",
       "      <td>-0.003326</td>\n",
       "      <td>-0.128414</td>\n",
       "      <td>-0.034918</td>\n",
       "      <td>5.40</td>\n",
       "      <td>False</td>\n",
       "      <td>5.22</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4766</td>\n",
       "      <td>5.86</td>\n",
       "      <td>5.89</td>\n",
       "      <td>5.45</td>\n",
       "      <td>5.50</td>\n",
       "      <td>5.50</td>\n",
       "      <td>91900</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>0.949397</td>\n",
       "      <td>-5.309082</td>\n",
       "      <td>0.150484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>-0.007590</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>-0.131153</td>\n",
       "      <td>-0.038893</td>\n",
       "      <td>5.41</td>\n",
       "      <td>False</td>\n",
       "      <td>5.39</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4767</td>\n",
       "      <td>5.67</td>\n",
       "      <td>5.80</td>\n",
       "      <td>5.46</td>\n",
       "      <td>5.56</td>\n",
       "      <td>5.56</td>\n",
       "      <td>128100</td>\n",
       "      <td>2020-04-29</td>\n",
       "      <td>-3.191791</td>\n",
       "      <td>10.897857</td>\n",
       "      <td>2.220444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255953</td>\n",
       "      <td>0.080357</td>\n",
       "      <td>0.061420</td>\n",
       "      <td>0.073027</td>\n",
       "      <td>-0.152699</td>\n",
       "      <td>-0.046825</td>\n",
       "      <td>5.22</td>\n",
       "      <td>False</td>\n",
       "      <td>5.41</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4768</td>\n",
       "      <td>5.50</td>\n",
       "      <td>5.52</td>\n",
       "      <td>5.23</td>\n",
       "      <td>5.40</td>\n",
       "      <td>5.40</td>\n",
       "      <td>109900</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>-0.207548</td>\n",
       "      <td>-1.520152</td>\n",
       "      <td>1.034228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075000</td>\n",
       "      <td>0.049550</td>\n",
       "      <td>-0.084646</td>\n",
       "      <td>0.022673</td>\n",
       "      <td>-0.191791</td>\n",
       "      <td>-0.063314</td>\n",
       "      <td>5.39</td>\n",
       "      <td>False</td>\n",
       "      <td>5.46</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4769</td>\n",
       "      <td>5.24</td>\n",
       "      <td>5.41</td>\n",
       "      <td>5.21</td>\n",
       "      <td>5.41</td>\n",
       "      <td>5.41</td>\n",
       "      <td>94400</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>1.420517</td>\n",
       "      <td>2.922581</td>\n",
       "      <td>-2.585810</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.172840</td>\n",
       "      <td>-0.095023</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.197029</td>\n",
       "      <td>-0.050765</td>\n",
       "      <td>5.41</td>\n",
       "      <td>False</td>\n",
       "      <td>5.78</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4770</td>\n",
       "      <td>5.28</td>\n",
       "      <td>5.39</td>\n",
       "      <td>5.15</td>\n",
       "      <td>5.22</td>\n",
       "      <td>5.22</td>\n",
       "      <td>69100</td>\n",
       "      <td>2020-05-04</td>\n",
       "      <td>-0.594559</td>\n",
       "      <td>-2.204122</td>\n",
       "      <td>-1.472425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.509554</td>\n",
       "      <td>-0.160194</td>\n",
       "      <td>-0.068669</td>\n",
       "      <td>-0.028501</td>\n",
       "      <td>-0.211810</td>\n",
       "      <td>-0.044978</td>\n",
       "      <td>5.46</td>\n",
       "      <td>True</td>\n",
       "      <td>5.84</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 178 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Open  High   Low  Close  Adj Close  Volume       Date  Acc/Dist_ROC_5  \\\n",
       "4761  5.37  5.37  5.19   5.27       5.27   39900 2020-04-21       -1.072744   \n",
       "4762  5.33  5.48  5.27   5.30       5.30   51000 2020-04-22  -369815.888601   \n",
       "4763  5.30  5.60  5.19   5.45       5.45   89700 2020-04-23      -14.262400   \n",
       "4764  5.45  5.50  5.32   5.49       5.49   26900 2020-04-24        0.450915   \n",
       "4765  5.55  5.80  5.54   5.73       5.73   84500 2020-04-27       -9.796976   \n",
       "4766  5.86  5.89  5.45   5.50       5.50   91900 2020-04-28        0.949397   \n",
       "4767  5.67  5.80  5.46   5.56       5.56  128100 2020-04-29       -3.191791   \n",
       "4768  5.50  5.52  5.23   5.40       5.40  109900 2020-04-30       -0.207548   \n",
       "4769  5.24  5.41  5.21   5.41       5.41   94400 2020-05-01        1.420517   \n",
       "4770  5.28  5.39  5.15   5.22       5.22   69100 2020-05-04       -0.594559   \n",
       "\n",
       "      Acc/Dist_ROC_7  Acc/Dist_ROC_14  ...  Vortex_5  Vortex_7  Vortex_14  \\\n",
       "4761       -1.475947        -0.893971  ... -0.111111 -0.188811   0.012987   \n",
       "4762       -0.388044        -1.712670  ...  0.151163  0.081784   0.034711   \n",
       "4763       -0.605121        -1.486214  ...  0.131429  0.003846   0.016639   \n",
       "4764   242739.307573        -0.771792  ... -0.200000  0.142857   0.040636   \n",
       "4765      -22.492446        -1.454504  ...  0.178082  0.312500   0.104673   \n",
       "4766       -5.309082         0.150484  ...  0.451613  0.068182  -0.007590   \n",
       "4767       10.897857         2.220444  ...  0.255953  0.080357   0.061420   \n",
       "4768       -1.520152         1.034228  ... -0.075000  0.049550  -0.084646   \n",
       "4769        2.922581        -2.585810  ... -0.172840 -0.095023   0.002041   \n",
       "4770       -2.204122        -1.472425  ... -0.509554 -0.160194  -0.068669   \n",
       "\n",
       "      Vortex_21  Vortex_50  Vortex_100  Close3  Direction3  Close5  Direction5  \n",
       "4761  -0.041152  -0.135502   -0.061700    5.49        True    5.50        True  \n",
       "4762   0.058700  -0.136657   -0.051353    5.73        True    5.56        True  \n",
       "4763  -0.002132  -0.127584   -0.051791    5.50        True    5.40       False  \n",
       "4764  -0.009815  -0.132882   -0.050960    5.56        True    5.41       False  \n",
       "4765  -0.003326  -0.128414   -0.034918    5.40       False    5.22       False  \n",
       "4766   0.063291  -0.131153   -0.038893    5.41       False    5.39       False  \n",
       "4767   0.073027  -0.152699   -0.046825    5.22       False    5.41       False  \n",
       "4768   0.022673  -0.191791   -0.063314    5.39       False    5.46        True  \n",
       "4769   0.000000  -0.197029   -0.050765    5.41       False    5.78        True  \n",
       "4770  -0.028501  -0.211810   -0.044978    5.46        True    5.84        True  \n",
       "\n",
       "[10 rows x 178 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating next n day price\n",
    "data['Close5'] = data['Close'].shift(-5)\n",
    "\n",
    "# Calculating next n direction\n",
    "data['Direction5'] = data['Close5'] > data['Close']\n",
    "data = data.dropna()\n",
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4138, 175)\n",
      "(4138,)\n",
      "(128, 175)\n",
      "(128,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Acc/Dist_ROC_5</th>\n",
       "      <th>Acc/Dist_ROC_7</th>\n",
       "      <th>Acc/Dist_ROC_14</th>\n",
       "      <th>Acc/Dist_ROC_21</th>\n",
       "      <th>...</th>\n",
       "      <th>Trix_100</th>\n",
       "      <th>Ultimate_Osc</th>\n",
       "      <th>Vortex_5</th>\n",
       "      <th>Vortex_7</th>\n",
       "      <th>Vortex_14</th>\n",
       "      <th>Vortex_21</th>\n",
       "      <th>Vortex_50</th>\n",
       "      <th>Vortex_100</th>\n",
       "      <th>Close3</th>\n",
       "      <th>Direction3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>901</td>\n",
       "      <td>0.453776</td>\n",
       "      <td>0.453739</td>\n",
       "      <td>0.459157</td>\n",
       "      <td>0.456282</td>\n",
       "      <td>0.456092</td>\n",
       "      <td>0.019235</td>\n",
       "      <td>0.297820</td>\n",
       "      <td>0.670023</td>\n",
       "      <td>0.287201</td>\n",
       "      <td>0.459816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455186</td>\n",
       "      <td>0.470693</td>\n",
       "      <td>0.579914</td>\n",
       "      <td>0.501471</td>\n",
       "      <td>0.428871</td>\n",
       "      <td>0.335080</td>\n",
       "      <td>0.475754</td>\n",
       "      <td>0.489998</td>\n",
       "      <td>0.463073</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4235</td>\n",
       "      <td>0.090291</td>\n",
       "      <td>0.088539</td>\n",
       "      <td>0.072922</td>\n",
       "      <td>0.076848</td>\n",
       "      <td>0.229662</td>\n",
       "      <td>0.054741</td>\n",
       "      <td>0.297820</td>\n",
       "      <td>0.670024</td>\n",
       "      <td>0.287201</td>\n",
       "      <td>0.459815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477350</td>\n",
       "      <td>0.437436</td>\n",
       "      <td>0.573628</td>\n",
       "      <td>0.504240</td>\n",
       "      <td>0.404427</td>\n",
       "      <td>0.366646</td>\n",
       "      <td>0.462747</td>\n",
       "      <td>0.499485</td>\n",
       "      <td>0.080195</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>803</td>\n",
       "      <td>0.503740</td>\n",
       "      <td>0.501056</td>\n",
       "      <td>0.499140</td>\n",
       "      <td>0.492784</td>\n",
       "      <td>0.492607</td>\n",
       "      <td>0.047954</td>\n",
       "      <td>0.297814</td>\n",
       "      <td>0.670022</td>\n",
       "      <td>0.287201</td>\n",
       "      <td>0.459815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.446822</td>\n",
       "      <td>0.334446</td>\n",
       "      <td>0.504230</td>\n",
       "      <td>0.490396</td>\n",
       "      <td>0.449016</td>\n",
       "      <td>0.512057</td>\n",
       "      <td>0.429460</td>\n",
       "      <td>0.433874</td>\n",
       "      <td>0.490662</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1826</td>\n",
       "      <td>0.083698</td>\n",
       "      <td>0.085199</td>\n",
       "      <td>0.085555</td>\n",
       "      <td>0.087012</td>\n",
       "      <td>0.090032</td>\n",
       "      <td>0.012981</td>\n",
       "      <td>0.297820</td>\n",
       "      <td>0.670022</td>\n",
       "      <td>0.287201</td>\n",
       "      <td>0.459816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.767062</td>\n",
       "      <td>0.407871</td>\n",
       "      <td>0.579244</td>\n",
       "      <td>0.622753</td>\n",
       "      <td>0.442865</td>\n",
       "      <td>0.750904</td>\n",
       "      <td>0.777933</td>\n",
       "      <td>0.808527</td>\n",
       "      <td>0.091256</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>657</td>\n",
       "      <td>0.610021</td>\n",
       "      <td>0.609210</td>\n",
       "      <td>0.618659</td>\n",
       "      <td>0.613328</td>\n",
       "      <td>0.613193</td>\n",
       "      <td>0.032809</td>\n",
       "      <td>0.271998</td>\n",
       "      <td>0.670024</td>\n",
       "      <td>0.287200</td>\n",
       "      <td>0.459816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447181</td>\n",
       "      <td>0.613012</td>\n",
       "      <td>0.489296</td>\n",
       "      <td>0.602617</td>\n",
       "      <td>0.434710</td>\n",
       "      <td>0.304014</td>\n",
       "      <td>0.593964</td>\n",
       "      <td>0.619752</td>\n",
       "      <td>0.616299</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Open      High       Low     Close  Adj Close    Volume  \\\n",
       "901   0.453776  0.453739  0.459157  0.456282   0.456092  0.019235   \n",
       "4235  0.090291  0.088539  0.072922  0.076848   0.229662  0.054741   \n",
       "803   0.503740  0.501056  0.499140  0.492784   0.492607  0.047954   \n",
       "1826  0.083698  0.085199  0.085555  0.087012   0.090032  0.012981   \n",
       "657   0.610021  0.609210  0.618659  0.613328   0.613193  0.032809   \n",
       "\n",
       "      Acc/Dist_ROC_5  Acc/Dist_ROC_7  Acc/Dist_ROC_14  Acc/Dist_ROC_21  ...  \\\n",
       "901         0.297820        0.670023         0.287201         0.459816  ...   \n",
       "4235        0.297820        0.670024         0.287201         0.459815  ...   \n",
       "803         0.297814        0.670022         0.287201         0.459815  ...   \n",
       "1826        0.297820        0.670022         0.287201         0.459816  ...   \n",
       "657         0.271998        0.670024         0.287200         0.459816  ...   \n",
       "\n",
       "      Trix_100  Ultimate_Osc  Vortex_5  Vortex_7  Vortex_14  Vortex_21  \\\n",
       "901   0.455186      0.470693  0.579914  0.501471   0.428871   0.335080   \n",
       "4235  0.477350      0.437436  0.573628  0.504240   0.404427   0.366646   \n",
       "803   0.446822      0.334446  0.504230  0.490396   0.449016   0.512057   \n",
       "1826  0.767062      0.407871  0.579244  0.622753   0.442865   0.750904   \n",
       "657   0.447181      0.613012  0.489296  0.602617   0.434710   0.304014   \n",
       "\n",
       "      Vortex_50  Vortex_100    Close3  Direction3  \n",
       "901    0.475754    0.489998  0.463073         1.0  \n",
       "4235   0.462747    0.499485  0.080195         1.0  \n",
       "803    0.429460    0.433874  0.490662         0.0  \n",
       "1826   0.777933    0.808527  0.091256         1.0  \n",
       "657    0.593964    0.619752  0.616299         1.0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X,y = data.drop(['Close5','Direction5','Date'],axis=1),data['Direction5']\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_inputs = scaler.fit_transform(X)\n",
    "scaled_inputs = pd.DataFrame(scaled_inputs,columns=X.columns)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(scaled_inputs,y,test_size=.03,random_state=101)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4138 samples, validate on 128 samples\n",
      "Epoch 1/300\n",
      " - 0s - loss: 0.6239 - accuracy: 0.7003 - val_loss: 0.5752 - val_accuracy: 0.7344\n",
      "Epoch 2/300\n",
      " - 0s - loss: 0.5339 - accuracy: 0.7818 - val_loss: 0.5720 - val_accuracy: 0.7344\n",
      "Epoch 3/300\n",
      " - 0s - loss: 0.5273 - accuracy: 0.7811 - val_loss: 0.5629 - val_accuracy: 0.7344\n",
      "Epoch 4/300\n",
      " - 0s - loss: 0.5264 - accuracy: 0.7820 - val_loss: 0.5530 - val_accuracy: 0.7344\n",
      "Epoch 5/300\n",
      " - 0s - loss: 0.5226 - accuracy: 0.7823 - val_loss: 0.5789 - val_accuracy: 0.7344\n",
      "Epoch 6/300\n",
      " - 0s - loss: 0.5180 - accuracy: 0.7820 - val_loss: 0.5654 - val_accuracy: 0.7266\n",
      "Epoch 7/300\n",
      " - 0s - loss: 0.5253 - accuracy: 0.7803 - val_loss: 0.5765 - val_accuracy: 0.7344\n",
      "Epoch 8/300\n",
      " - 0s - loss: 0.5204 - accuracy: 0.7820 - val_loss: 0.5659 - val_accuracy: 0.7344\n",
      "Epoch 9/300\n",
      " - 0s - loss: 0.5225 - accuracy: 0.7825 - val_loss: 0.5648 - val_accuracy: 0.7344\n",
      "Epoch 10/300\n",
      " - 0s - loss: 0.5173 - accuracy: 0.7820 - val_loss: 0.5645 - val_accuracy: 0.7344\n",
      "Epoch 11/300\n",
      " - 0s - loss: 0.5153 - accuracy: 0.7835 - val_loss: 0.5663 - val_accuracy: 0.7344\n",
      "Epoch 12/300\n",
      " - 0s - loss: 0.5152 - accuracy: 0.7825 - val_loss: 0.5683 - val_accuracy: 0.7344\n",
      "Epoch 13/300\n",
      " - 0s - loss: 0.5142 - accuracy: 0.7820 - val_loss: 0.5459 - val_accuracy: 0.7344\n",
      "Epoch 14/300\n",
      " - 0s - loss: 0.5194 - accuracy: 0.7815 - val_loss: 0.5883 - val_accuracy: 0.7344\n",
      "Epoch 15/300\n",
      " - 0s - loss: 0.5162 - accuracy: 0.7825 - val_loss: 0.5646 - val_accuracy: 0.7344\n",
      "Epoch 16/300\n",
      " - 0s - loss: 0.5128 - accuracy: 0.7830 - val_loss: 0.5603 - val_accuracy: 0.7344\n",
      "Epoch 17/300\n",
      " - 0s - loss: 0.5148 - accuracy: 0.7823 - val_loss: 0.5852 - val_accuracy: 0.7344\n",
      "Epoch 18/300\n",
      " - 0s - loss: 0.5106 - accuracy: 0.7827 - val_loss: 0.5620 - val_accuracy: 0.7422\n",
      "Epoch 19/300\n",
      " - 0s - loss: 0.5136 - accuracy: 0.7847 - val_loss: 0.5767 - val_accuracy: 0.7344\n",
      "Epoch 20/300\n",
      " - 0s - loss: 0.5122 - accuracy: 0.7820 - val_loss: 0.5619 - val_accuracy: 0.7344\n",
      "Epoch 21/300\n",
      " - 0s - loss: 0.5136 - accuracy: 0.7823 - val_loss: 0.5794 - val_accuracy: 0.7344\n",
      "Epoch 22/300\n",
      " - 0s - loss: 0.5091 - accuracy: 0.7827 - val_loss: 0.5719 - val_accuracy: 0.7344\n",
      "Epoch 23/300\n",
      " - 0s - loss: 0.5076 - accuracy: 0.7832 - val_loss: 0.5376 - val_accuracy: 0.7344\n",
      "Epoch 24/300\n",
      " - 0s - loss: 0.5031 - accuracy: 0.7844 - val_loss: 0.5565 - val_accuracy: 0.7344\n",
      "Epoch 25/300\n",
      " - 0s - loss: 0.5096 - accuracy: 0.7818 - val_loss: 0.5643 - val_accuracy: 0.7344\n",
      "Epoch 26/300\n",
      " - 0s - loss: 0.5032 - accuracy: 0.7842 - val_loss: 0.5606 - val_accuracy: 0.7344\n",
      "Epoch 27/300\n",
      " - 0s - loss: 0.5054 - accuracy: 0.7856 - val_loss: 0.5469 - val_accuracy: 0.7422\n",
      "Epoch 28/300\n",
      " - 0s - loss: 0.5092 - accuracy: 0.7825 - val_loss: 0.5739 - val_accuracy: 0.7344\n",
      "Epoch 29/300\n",
      " - 0s - loss: 0.5011 - accuracy: 0.7840 - val_loss: 0.5541 - val_accuracy: 0.7422\n",
      "Epoch 30/300\n",
      " - 0s - loss: 0.5002 - accuracy: 0.7856 - val_loss: 0.5534 - val_accuracy: 0.7344\n",
      "Epoch 31/300\n",
      " - 0s - loss: 0.4995 - accuracy: 0.7840 - val_loss: 0.5364 - val_accuracy: 0.7422\n",
      "Epoch 32/300\n",
      " - 0s - loss: 0.4987 - accuracy: 0.7837 - val_loss: 0.5471 - val_accuracy: 0.7422\n",
      "Epoch 33/300\n",
      " - 0s - loss: 0.4942 - accuracy: 0.7842 - val_loss: 0.5554 - val_accuracy: 0.7422\n",
      "Epoch 34/300\n",
      " - 0s - loss: 0.4972 - accuracy: 0.7849 - val_loss: 0.6110 - val_accuracy: 0.7422\n",
      "Epoch 35/300\n",
      " - 0s - loss: 0.4926 - accuracy: 0.7854 - val_loss: 0.5523 - val_accuracy: 0.7344\n",
      "Epoch 36/300\n",
      " - 0s - loss: 0.4955 - accuracy: 0.7861 - val_loss: 0.5527 - val_accuracy: 0.7422\n",
      "Epoch 37/300\n",
      " - 0s - loss: 0.4913 - accuracy: 0.7864 - val_loss: 0.5557 - val_accuracy: 0.7344\n",
      "Epoch 38/300\n",
      " - 0s - loss: 0.4880 - accuracy: 0.7854 - val_loss: 0.5640 - val_accuracy: 0.7344\n",
      "Epoch 39/300\n",
      " - 0s - loss: 0.4876 - accuracy: 0.7881 - val_loss: 0.5352 - val_accuracy: 0.7266\n",
      "Epoch 40/300\n",
      " - 0s - loss: 0.4939 - accuracy: 0.7869 - val_loss: 0.5200 - val_accuracy: 0.7422\n",
      "Epoch 41/300\n",
      " - 0s - loss: 0.4834 - accuracy: 0.7876 - val_loss: 0.5544 - val_accuracy: 0.7422\n",
      "Epoch 42/300\n",
      " - 0s - loss: 0.4844 - accuracy: 0.7881 - val_loss: 0.5626 - val_accuracy: 0.7344\n",
      "Epoch 43/300\n",
      " - 0s - loss: 0.4801 - accuracy: 0.7919 - val_loss: 0.5348 - val_accuracy: 0.7266\n",
      "Epoch 44/300\n",
      " - 0s - loss: 0.4786 - accuracy: 0.7883 - val_loss: 0.5213 - val_accuracy: 0.7422\n",
      "Epoch 45/300\n",
      " - 0s - loss: 0.4755 - accuracy: 0.7895 - val_loss: 0.5391 - val_accuracy: 0.7500\n",
      "Epoch 46/300\n",
      " - 0s - loss: 0.4889 - accuracy: 0.7876 - val_loss: 0.5599 - val_accuracy: 0.7578\n",
      "Epoch 47/300\n",
      " - 0s - loss: 0.4750 - accuracy: 0.7910 - val_loss: 0.4965 - val_accuracy: 0.7344\n",
      "Epoch 48/300\n",
      " - 0s - loss: 0.4722 - accuracy: 0.7912 - val_loss: 0.5327 - val_accuracy: 0.7422\n",
      "Epoch 49/300\n",
      " - 0s - loss: 0.4735 - accuracy: 0.7927 - val_loss: 0.5458 - val_accuracy: 0.7578\n",
      "Epoch 50/300\n",
      " - 0s - loss: 0.4745 - accuracy: 0.7919 - val_loss: 0.5527 - val_accuracy: 0.7578\n",
      "Epoch 51/300\n",
      " - 0s - loss: 0.4749 - accuracy: 0.7922 - val_loss: 0.5020 - val_accuracy: 0.7734\n",
      "Epoch 52/300\n",
      " - 0s - loss: 0.4764 - accuracy: 0.7898 - val_loss: 0.5372 - val_accuracy: 0.7578\n",
      "Epoch 53/300\n",
      " - 0s - loss: 0.4662 - accuracy: 0.7943 - val_loss: 0.5497 - val_accuracy: 0.7344\n",
      "Epoch 54/300\n",
      " - 0s - loss: 0.4709 - accuracy: 0.7931 - val_loss: 0.5621 - val_accuracy: 0.7500\n",
      "Epoch 55/300\n",
      " - 0s - loss: 0.4674 - accuracy: 0.7924 - val_loss: 0.5565 - val_accuracy: 0.7422\n",
      "Epoch 56/300\n",
      " - 0s - loss: 0.4624 - accuracy: 0.7948 - val_loss: 0.5456 - val_accuracy: 0.7500\n",
      "Epoch 57/300\n",
      " - 0s - loss: 0.4600 - accuracy: 0.7985 - val_loss: 0.5331 - val_accuracy: 0.7578\n",
      "Epoch 58/300\n",
      " - 0s - loss: 0.4552 - accuracy: 0.7992 - val_loss: 0.5623 - val_accuracy: 0.7422\n",
      "Epoch 59/300\n",
      " - 0s - loss: 0.4598 - accuracy: 0.7941 - val_loss: 0.5371 - val_accuracy: 0.7500\n",
      "Epoch 60/300\n",
      " - 0s - loss: 0.4582 - accuracy: 0.7941 - val_loss: 0.5511 - val_accuracy: 0.7500\n",
      "Epoch 61/300\n",
      " - 0s - loss: 0.4602 - accuracy: 0.7914 - val_loss: 0.5162 - val_accuracy: 0.7656\n",
      "Epoch 62/300\n",
      " - 0s - loss: 0.4497 - accuracy: 0.7997 - val_loss: 0.5474 - val_accuracy: 0.7422\n",
      "Epoch 63/300\n",
      " - 0s - loss: 0.4459 - accuracy: 0.8009 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 64/300\n",
      " - 0s - loss: 0.4452 - accuracy: 0.8045 - val_loss: 0.5238 - val_accuracy: 0.7734\n",
      "Epoch 65/300\n",
      " - 0s - loss: 0.4397 - accuracy: 0.8004 - val_loss: 0.5249 - val_accuracy: 0.7734\n",
      "Epoch 66/300\n",
      " - 0s - loss: 0.4408 - accuracy: 0.8018 - val_loss: 0.5979 - val_accuracy: 0.7656\n",
      "Epoch 67/300\n",
      " - 0s - loss: 0.4482 - accuracy: 0.8004 - val_loss: 0.5193 - val_accuracy: 0.7578\n",
      "Epoch 68/300\n",
      " - 0s - loss: 0.4405 - accuracy: 0.8011 - val_loss: 0.5514 - val_accuracy: 0.7578\n",
      "Epoch 69/300\n",
      " - 0s - loss: 0.4367 - accuracy: 0.8079 - val_loss: 0.5771 - val_accuracy: 0.7500\n",
      "Epoch 70/300\n",
      " - 0s - loss: 0.4362 - accuracy: 0.8047 - val_loss: 0.5199 - val_accuracy: 0.7656\n",
      "Epoch 71/300\n",
      " - 0s - loss: 0.4339 - accuracy: 0.8057 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
      "Epoch 72/300\n",
      " - 0s - loss: 0.4260 - accuracy: 0.8098 - val_loss: 0.5727 - val_accuracy: 0.7812\n",
      "Epoch 73/300\n",
      " - 0s - loss: 0.4377 - accuracy: 0.8047 - val_loss: 0.5362 - val_accuracy: 0.7500\n",
      "Epoch 74/300\n",
      " - 0s - loss: 0.4278 - accuracy: 0.8045 - val_loss: 0.5249 - val_accuracy: 0.7422\n",
      "Epoch 75/300\n",
      " - 0s - loss: 0.4175 - accuracy: 0.8103 - val_loss: 0.5084 - val_accuracy: 0.7578\n",
      "Epoch 76/300\n",
      " - 0s - loss: 0.4138 - accuracy: 0.8115 - val_loss: 0.5319 - val_accuracy: 0.7500\n",
      "Epoch 77/300\n",
      " - 0s - loss: 0.4148 - accuracy: 0.8139 - val_loss: 0.5560 - val_accuracy: 0.7500\n",
      "Epoch 78/300\n",
      " - 0s - loss: 0.4305 - accuracy: 0.8072 - val_loss: 0.5223 - val_accuracy: 0.7734\n",
      "Epoch 79/300\n",
      " - 0s - loss: 0.4188 - accuracy: 0.8117 - val_loss: 0.5318 - val_accuracy: 0.7734\n",
      "Epoch 80/300\n",
      " - 0s - loss: 0.4152 - accuracy: 0.8108 - val_loss: 0.5147 - val_accuracy: 0.7734\n",
      "Epoch 81/300\n",
      " - 0s - loss: 0.4208 - accuracy: 0.8057 - val_loss: 0.5043 - val_accuracy: 0.7891\n",
      "Epoch 82/300\n",
      " - 0s - loss: 0.4104 - accuracy: 0.8117 - val_loss: 0.6101 - val_accuracy: 0.7500\n",
      "Epoch 83/300\n",
      " - 0s - loss: 0.4130 - accuracy: 0.8197 - val_loss: 0.4823 - val_accuracy: 0.7812\n",
      "Epoch 84/300\n",
      " - 0s - loss: 0.3999 - accuracy: 0.8209 - val_loss: 0.5217 - val_accuracy: 0.7656\n",
      "Epoch 85/300\n",
      " - 0s - loss: 0.3976 - accuracy: 0.8229 - val_loss: 0.5102 - val_accuracy: 0.7891\n",
      "Epoch 86/300\n",
      " - 0s - loss: 0.3948 - accuracy: 0.8166 - val_loss: 0.5567 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/300\n",
      " - 0s - loss: 0.3909 - accuracy: 0.8258 - val_loss: 0.5260 - val_accuracy: 0.7734\n",
      "Epoch 88/300\n",
      " - 0s - loss: 0.3919 - accuracy: 0.8253 - val_loss: 0.4896 - val_accuracy: 0.7891\n",
      "Epoch 89/300\n",
      " - 0s - loss: 0.3853 - accuracy: 0.8282 - val_loss: 0.5189 - val_accuracy: 0.7969\n",
      "Epoch 90/300\n",
      " - 0s - loss: 0.3792 - accuracy: 0.8248 - val_loss: 0.5934 - val_accuracy: 0.7578\n",
      "Epoch 91/300\n",
      " - 0s - loss: 0.3905 - accuracy: 0.8217 - val_loss: 0.4757 - val_accuracy: 0.7578\n",
      "Epoch 92/300\n",
      " - 0s - loss: 0.3868 - accuracy: 0.8284 - val_loss: 0.5458 - val_accuracy: 0.7969\n",
      "Epoch 93/300\n",
      " - 0s - loss: 0.3789 - accuracy: 0.8287 - val_loss: 0.5270 - val_accuracy: 0.7812\n",
      "Epoch 94/300\n",
      " - 0s - loss: 0.3706 - accuracy: 0.8369 - val_loss: 0.5166 - val_accuracy: 0.7734\n",
      "Epoch 95/300\n",
      " - 0s - loss: 0.3603 - accuracy: 0.8458 - val_loss: 0.5442 - val_accuracy: 0.7656\n",
      "Epoch 96/300\n",
      " - 0s - loss: 0.3822 - accuracy: 0.8226 - val_loss: 0.5158 - val_accuracy: 0.7891\n",
      "Epoch 97/300\n",
      " - 0s - loss: 0.3667 - accuracy: 0.8383 - val_loss: 0.5587 - val_accuracy: 0.7266\n",
      "Epoch 98/300\n",
      " - 0s - loss: 0.3798 - accuracy: 0.8250 - val_loss: 0.5272 - val_accuracy: 0.7578\n",
      "Epoch 99/300\n",
      " - 0s - loss: 0.3556 - accuracy: 0.8424 - val_loss: 0.5340 - val_accuracy: 0.7812\n",
      "Epoch 100/300\n",
      " - 0s - loss: 0.3650 - accuracy: 0.8400 - val_loss: 0.5699 - val_accuracy: 0.7812\n",
      "Epoch 101/300\n",
      " - 0s - loss: 0.3604 - accuracy: 0.8412 - val_loss: 0.5667 - val_accuracy: 0.7812\n",
      "Epoch 102/300\n",
      " - 0s - loss: 0.3618 - accuracy: 0.8388 - val_loss: 0.4970 - val_accuracy: 0.7969\n",
      "Epoch 103/300\n",
      " - 0s - loss: 0.3565 - accuracy: 0.8441 - val_loss: 0.5597 - val_accuracy: 0.7891\n",
      "Epoch 104/300\n",
      " - 0s - loss: 0.3456 - accuracy: 0.8444 - val_loss: 0.6433 - val_accuracy: 0.7578\n",
      "Epoch 105/300\n",
      " - 0s - loss: 0.3411 - accuracy: 0.8480 - val_loss: 0.5670 - val_accuracy: 0.7500\n",
      "Epoch 106/300\n",
      " - 0s - loss: 0.3481 - accuracy: 0.8446 - val_loss: 0.5239 - val_accuracy: 0.7656\n",
      "Epoch 107/300\n",
      " - 0s - loss: 0.3506 - accuracy: 0.8439 - val_loss: 0.5344 - val_accuracy: 0.7812\n",
      "Epoch 108/300\n",
      " - 0s - loss: 0.3448 - accuracy: 0.8415 - val_loss: 0.5856 - val_accuracy: 0.7656\n",
      "Epoch 109/300\n",
      " - 0s - loss: 0.3360 - accuracy: 0.8494 - val_loss: 0.5888 - val_accuracy: 0.8047\n",
      "Epoch 110/300\n",
      " - 0s - loss: 0.3382 - accuracy: 0.8490 - val_loss: 0.5492 - val_accuracy: 0.7812\n",
      "Epoch 111/300\n",
      " - 0s - loss: 0.3364 - accuracy: 0.8463 - val_loss: 0.5772 - val_accuracy: 0.7891\n",
      "Epoch 112/300\n",
      " - 0s - loss: 0.3205 - accuracy: 0.8569 - val_loss: 0.4996 - val_accuracy: 0.7812\n",
      "Epoch 113/300\n",
      " - 0s - loss: 0.3276 - accuracy: 0.8519 - val_loss: 0.5841 - val_accuracy: 0.7812\n",
      "Epoch 114/300\n",
      " - 0s - loss: 0.3124 - accuracy: 0.8623 - val_loss: 0.5464 - val_accuracy: 0.7812\n",
      "Epoch 115/300\n",
      " - 0s - loss: 0.3088 - accuracy: 0.8635 - val_loss: 0.5430 - val_accuracy: 0.8125\n",
      "Epoch 116/300\n",
      " - 0s - loss: 0.3233 - accuracy: 0.8521 - val_loss: 0.5909 - val_accuracy: 0.7578\n",
      "Epoch 117/300\n",
      " - 0s - loss: 0.3123 - accuracy: 0.8618 - val_loss: 0.5848 - val_accuracy: 0.7812\n",
      "Epoch 118/300\n",
      " - 0s - loss: 0.3220 - accuracy: 0.8552 - val_loss: 0.5054 - val_accuracy: 0.7891\n",
      "Epoch 119/300\n",
      " - 0s - loss: 0.3210 - accuracy: 0.8635 - val_loss: 0.5906 - val_accuracy: 0.7734\n",
      "Epoch 120/300\n",
      " - 0s - loss: 0.3235 - accuracy: 0.8533 - val_loss: 0.5709 - val_accuracy: 0.7812\n",
      "Epoch 121/300\n",
      " - 0s - loss: 0.2944 - accuracy: 0.8724 - val_loss: 0.6364 - val_accuracy: 0.7656\n",
      "Epoch 122/300\n",
      " - 0s - loss: 0.3113 - accuracy: 0.8608 - val_loss: 0.6475 - val_accuracy: 0.7422\n",
      "Epoch 123/300\n",
      " - 0s - loss: 0.3022 - accuracy: 0.8702 - val_loss: 0.5542 - val_accuracy: 0.7734\n",
      "Epoch 124/300\n",
      " - 0s - loss: 0.2884 - accuracy: 0.8693 - val_loss: 0.5900 - val_accuracy: 0.7812\n",
      "Epoch 125/300\n",
      " - 0s - loss: 0.2892 - accuracy: 0.8702 - val_loss: 0.5690 - val_accuracy: 0.7812\n",
      "Epoch 126/300\n",
      " - 0s - loss: 0.2941 - accuracy: 0.8681 - val_loss: 0.6151 - val_accuracy: 0.7812\n",
      "Epoch 127/300\n",
      " - 0s - loss: 0.2896 - accuracy: 0.8697 - val_loss: 0.5272 - val_accuracy: 0.7656\n",
      "Epoch 128/300\n",
      " - 0s - loss: 0.2735 - accuracy: 0.8842 - val_loss: 0.5535 - val_accuracy: 0.7734\n",
      "Epoch 129/300\n",
      " - 0s - loss: 0.2724 - accuracy: 0.8792 - val_loss: 0.5417 - val_accuracy: 0.7812\n",
      "Epoch 130/300\n",
      " - 0s - loss: 0.2785 - accuracy: 0.8782 - val_loss: 0.5456 - val_accuracy: 0.8125\n",
      "Epoch 131/300\n",
      " - 0s - loss: 0.2607 - accuracy: 0.8855 - val_loss: 0.6971 - val_accuracy: 0.7500\n",
      "Epoch 132/300\n",
      " - 0s - loss: 0.2892 - accuracy: 0.8760 - val_loss: 0.6326 - val_accuracy: 0.8047\n",
      "Epoch 133/300\n",
      " - 0s - loss: 0.2609 - accuracy: 0.8864 - val_loss: 0.6268 - val_accuracy: 0.7578\n",
      "Epoch 134/300\n",
      " - 0s - loss: 0.2552 - accuracy: 0.8886 - val_loss: 0.6372 - val_accuracy: 0.7812\n",
      "Epoch 135/300\n",
      " - 0s - loss: 0.2633 - accuracy: 0.8859 - val_loss: 0.6094 - val_accuracy: 0.7969\n",
      "Epoch 136/300\n",
      " - 0s - loss: 0.2682 - accuracy: 0.8789 - val_loss: 0.5677 - val_accuracy: 0.7891\n",
      "Epoch 137/300\n",
      " - 0s - loss: 0.2894 - accuracy: 0.8666 - val_loss: 0.6249 - val_accuracy: 0.7656\n",
      "Epoch 138/300\n",
      " - 0s - loss: 0.2734 - accuracy: 0.8804 - val_loss: 0.5649 - val_accuracy: 0.7500\n",
      "Epoch 139/300\n",
      " - 0s - loss: 0.2474 - accuracy: 0.8910 - val_loss: 0.6478 - val_accuracy: 0.8047\n",
      "Epoch 140/300\n",
      " - 0s - loss: 0.2596 - accuracy: 0.8847 - val_loss: 0.6418 - val_accuracy: 0.7812\n",
      "Epoch 141/300\n",
      " - 0s - loss: 0.2565 - accuracy: 0.8850 - val_loss: 0.7285 - val_accuracy: 0.7812\n",
      "Epoch 142/300\n",
      " - 0s - loss: 0.2583 - accuracy: 0.8852 - val_loss: 0.6987 - val_accuracy: 0.7500\n",
      "Epoch 143/300\n",
      " - 0s - loss: 0.2495 - accuracy: 0.8898 - val_loss: 0.5862 - val_accuracy: 0.7812\n",
      "Epoch 144/300\n",
      " - 0s - loss: 0.2319 - accuracy: 0.9007 - val_loss: 0.5888 - val_accuracy: 0.8203\n",
      "Epoch 145/300\n",
      " - 0s - loss: 0.2262 - accuracy: 0.9016 - val_loss: 0.6465 - val_accuracy: 0.7734\n",
      "Epoch 146/300\n",
      " - 0s - loss: 0.2484 - accuracy: 0.8915 - val_loss: 0.7558 - val_accuracy: 0.7734\n",
      "Epoch 147/300\n",
      " - 0s - loss: 0.2383 - accuracy: 0.8956 - val_loss: 0.5962 - val_accuracy: 0.7734\n",
      "Epoch 148/300\n",
      " - 0s - loss: 0.2294 - accuracy: 0.8985 - val_loss: 0.7297 - val_accuracy: 0.7734\n",
      "Epoch 149/300\n",
      " - 0s - loss: 0.2257 - accuracy: 0.9036 - val_loss: 0.6193 - val_accuracy: 0.7734\n",
      "Epoch 150/300\n",
      " - 0s - loss: 0.2180 - accuracy: 0.9128 - val_loss: 0.7088 - val_accuracy: 0.7578\n",
      "Epoch 151/300\n",
      " - 0s - loss: 0.2114 - accuracy: 0.9094 - val_loss: 0.6581 - val_accuracy: 0.7656\n",
      "Epoch 152/300\n",
      " - 0s - loss: 0.2310 - accuracy: 0.9045 - val_loss: 0.6369 - val_accuracy: 0.7891\n",
      "Epoch 153/300\n",
      " - 0s - loss: 0.2325 - accuracy: 0.8939 - val_loss: 0.6609 - val_accuracy: 0.8203\n",
      "Epoch 154/300\n",
      " - 0s - loss: 0.2341 - accuracy: 0.8980 - val_loss: 0.7103 - val_accuracy: 0.7969\n",
      "Epoch 155/300\n",
      " - 0s - loss: 0.2071 - accuracy: 0.9125 - val_loss: 0.7683 - val_accuracy: 0.7500\n",
      "Epoch 156/300\n",
      " - 0s - loss: 0.2130 - accuracy: 0.9128 - val_loss: 0.7039 - val_accuracy: 0.7422\n",
      "Epoch 157/300\n",
      " - 0s - loss: 0.2114 - accuracy: 0.9125 - val_loss: 0.6747 - val_accuracy: 0.8047\n",
      "Epoch 158/300\n",
      " - 0s - loss: 0.2113 - accuracy: 0.9120 - val_loss: 0.6431 - val_accuracy: 0.7422\n",
      "Epoch 159/300\n",
      " - 0s - loss: 0.2036 - accuracy: 0.9137 - val_loss: 0.7482 - val_accuracy: 0.7656\n",
      "Epoch 160/300\n",
      " - 0s - loss: 0.2025 - accuracy: 0.9103 - val_loss: 0.8204 - val_accuracy: 0.8047\n",
      "Epoch 161/300\n",
      " - 0s - loss: 0.2117 - accuracy: 0.9099 - val_loss: 0.7399 - val_accuracy: 0.7500\n",
      "Epoch 162/300\n",
      " - 0s - loss: 0.2167 - accuracy: 0.9029 - val_loss: 0.7248 - val_accuracy: 0.7969\n",
      "Epoch 163/300\n",
      " - 0s - loss: 0.2056 - accuracy: 0.9116 - val_loss: 0.6443 - val_accuracy: 0.7578\n",
      "Epoch 164/300\n",
      " - 0s - loss: 0.1950 - accuracy: 0.9161 - val_loss: 0.7423 - val_accuracy: 0.7969\n",
      "Epoch 165/300\n",
      " - 0s - loss: 0.1860 - accuracy: 0.9219 - val_loss: 0.7278 - val_accuracy: 0.7578\n",
      "Epoch 166/300\n",
      " - 0s - loss: 0.1971 - accuracy: 0.9130 - val_loss: 0.6888 - val_accuracy: 0.7734\n",
      "Epoch 167/300\n",
      " - 0s - loss: 0.1854 - accuracy: 0.9246 - val_loss: 0.6945 - val_accuracy: 0.7812\n",
      "Epoch 168/300\n",
      " - 0s - loss: 0.1811 - accuracy: 0.9244 - val_loss: 0.6687 - val_accuracy: 0.7812\n",
      "Epoch 169/300\n",
      " - 0s - loss: 0.1821 - accuracy: 0.9236 - val_loss: 0.6838 - val_accuracy: 0.7891\n",
      "Epoch 170/300\n",
      " - 0s - loss: 0.1775 - accuracy: 0.9251 - val_loss: 0.7270 - val_accuracy: 0.7734\n",
      "Epoch 171/300\n",
      " - 0s - loss: 0.1654 - accuracy: 0.9314 - val_loss: 0.7413 - val_accuracy: 0.7891\n",
      "Epoch 172/300\n",
      " - 0s - loss: 0.1679 - accuracy: 0.9304 - val_loss: 0.7160 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/300\n",
      " - 0s - loss: 0.1524 - accuracy: 0.9369 - val_loss: 0.8192 - val_accuracy: 0.7656\n",
      "Epoch 174/300\n",
      " - 0s - loss: 0.1507 - accuracy: 0.9403 - val_loss: 0.8009 - val_accuracy: 0.7969\n",
      "Epoch 175/300\n",
      " - 0s - loss: 0.1612 - accuracy: 0.9345 - val_loss: 0.7673 - val_accuracy: 0.7500\n",
      "Epoch 176/300\n",
      " - 0s - loss: 0.1685 - accuracy: 0.9328 - val_loss: 0.6837 - val_accuracy: 0.8125\n",
      "Epoch 177/300\n",
      " - 0s - loss: 0.1640 - accuracy: 0.9357 - val_loss: 0.7489 - val_accuracy: 0.7500\n",
      "Epoch 178/300\n",
      " - 0s - loss: 0.1594 - accuracy: 0.9355 - val_loss: 0.8174 - val_accuracy: 0.7422\n",
      "Epoch 179/300\n",
      " - 0s - loss: 0.1578 - accuracy: 0.9340 - val_loss: 0.7539 - val_accuracy: 0.7578\n",
      "Epoch 180/300\n",
      " - 0s - loss: 0.1589 - accuracy: 0.9357 - val_loss: 0.8290 - val_accuracy: 0.7734\n",
      "Epoch 181/300\n",
      " - 0s - loss: 0.1625 - accuracy: 0.9369 - val_loss: 0.7855 - val_accuracy: 0.7500\n",
      "Epoch 182/300\n",
      " - 0s - loss: 0.1940 - accuracy: 0.9176 - val_loss: 0.8164 - val_accuracy: 0.7969\n",
      "Epoch 183/300\n",
      " - 0s - loss: 0.2091 - accuracy: 0.9130 - val_loss: 0.8129 - val_accuracy: 0.7812\n",
      "Epoch 184/300\n",
      " - 0s - loss: 0.1872 - accuracy: 0.9241 - val_loss: 0.7548 - val_accuracy: 0.7891\n",
      "Epoch 185/300\n",
      " - 0s - loss: 0.1585 - accuracy: 0.9364 - val_loss: 0.8584 - val_accuracy: 0.7734\n",
      "Epoch 186/300\n",
      " - 0s - loss: 0.1637 - accuracy: 0.9326 - val_loss: 0.7565 - val_accuracy: 0.8047\n",
      "Epoch 187/300\n",
      " - 0s - loss: 0.1458 - accuracy: 0.9364 - val_loss: 0.8765 - val_accuracy: 0.7109\n",
      "Epoch 188/300\n",
      " - 0s - loss: 0.1350 - accuracy: 0.9468 - val_loss: 0.8238 - val_accuracy: 0.8047\n",
      "Epoch 189/300\n",
      " - 0s - loss: 0.1350 - accuracy: 0.9464 - val_loss: 0.7725 - val_accuracy: 0.8047\n",
      "Epoch 190/300\n",
      " - 0s - loss: 0.1350 - accuracy: 0.9415 - val_loss: 0.7554 - val_accuracy: 0.7812\n",
      "Epoch 191/300\n",
      " - 0s - loss: 0.1430 - accuracy: 0.9444 - val_loss: 0.7967 - val_accuracy: 0.7578\n",
      "Epoch 192/300\n",
      " - 0s - loss: 0.1634 - accuracy: 0.9311 - val_loss: 0.7797 - val_accuracy: 0.7656\n",
      "Epoch 193/300\n",
      " - 0s - loss: 0.1364 - accuracy: 0.9442 - val_loss: 0.9833 - val_accuracy: 0.7656\n",
      "Epoch 194/300\n",
      " - 0s - loss: 0.1339 - accuracy: 0.9471 - val_loss: 0.8552 - val_accuracy: 0.8047\n",
      "Epoch 195/300\n",
      " - 0s - loss: 0.1195 - accuracy: 0.9531 - val_loss: 0.9363 - val_accuracy: 0.7578\n",
      "Epoch 196/300\n",
      " - 0s - loss: 0.1674 - accuracy: 0.9326 - val_loss: 0.9893 - val_accuracy: 0.7656\n",
      "Epoch 197/300\n",
      " - 0s - loss: 0.1599 - accuracy: 0.9314 - val_loss: 0.8453 - val_accuracy: 0.7891\n",
      "Epoch 198/300\n",
      " - 0s - loss: 0.1281 - accuracy: 0.9495 - val_loss: 0.8646 - val_accuracy: 0.7734\n",
      "Epoch 199/300\n",
      " - 0s - loss: 0.1183 - accuracy: 0.9541 - val_loss: 0.8835 - val_accuracy: 0.7812\n",
      "Epoch 200/300\n",
      " - 0s - loss: 0.1119 - accuracy: 0.9589 - val_loss: 0.8847 - val_accuracy: 0.7891\n",
      "Epoch 201/300\n",
      " - 0s - loss: 0.1133 - accuracy: 0.9596 - val_loss: 0.9866 - val_accuracy: 0.7734\n",
      "Epoch 202/300\n",
      " - 0s - loss: 0.1162 - accuracy: 0.9529 - val_loss: 0.8825 - val_accuracy: 0.7734\n",
      "Epoch 203/300\n",
      " - 0s - loss: 0.1255 - accuracy: 0.9466 - val_loss: 0.9139 - val_accuracy: 0.7891\n",
      "Epoch 204/300\n",
      " - 0s - loss: 0.1112 - accuracy: 0.9582 - val_loss: 0.9983 - val_accuracy: 0.7734\n",
      "Epoch 205/300\n",
      " - 0s - loss: 0.1199 - accuracy: 0.9502 - val_loss: 0.8893 - val_accuracy: 0.8047\n",
      "Epoch 206/300\n",
      " - 0s - loss: 0.1387 - accuracy: 0.9444 - val_loss: 1.0242 - val_accuracy: 0.7578\n",
      "Epoch 207/300\n",
      " - 0s - loss: 0.1405 - accuracy: 0.9403 - val_loss: 1.0875 - val_accuracy: 0.7656\n",
      "Epoch 208/300\n",
      " - 0s - loss: 0.1380 - accuracy: 0.9427 - val_loss: 1.1107 - val_accuracy: 0.8047\n",
      "Epoch 209/300\n",
      " - 0s - loss: 0.1291 - accuracy: 0.9451 - val_loss: 0.9822 - val_accuracy: 0.7969\n",
      "Epoch 210/300\n",
      " - 0s - loss: 0.1108 - accuracy: 0.9567 - val_loss: 0.7452 - val_accuracy: 0.8125\n",
      "Epoch 211/300\n",
      " - 0s - loss: 0.1371 - accuracy: 0.9444 - val_loss: 0.9477 - val_accuracy: 0.7812\n",
      "Epoch 212/300\n",
      " - 0s - loss: 0.1372 - accuracy: 0.9418 - val_loss: 1.0296 - val_accuracy: 0.7500\n",
      "Epoch 213/300\n",
      " - 0s - loss: 0.1405 - accuracy: 0.9439 - val_loss: 1.0524 - val_accuracy: 0.7812\n",
      "Epoch 214/300\n",
      " - 0s - loss: 0.0970 - accuracy: 0.9674 - val_loss: 0.9496 - val_accuracy: 0.7812\n",
      "Epoch 215/300\n",
      " - 0s - loss: 0.1103 - accuracy: 0.9541 - val_loss: 1.0318 - val_accuracy: 0.7656\n",
      "Epoch 216/300\n",
      " - 0s - loss: 0.1125 - accuracy: 0.9594 - val_loss: 1.0493 - val_accuracy: 0.7656\n",
      "Epoch 217/300\n",
      " - 0s - loss: 0.0880 - accuracy: 0.9679 - val_loss: 1.0456 - val_accuracy: 0.7656\n",
      "Epoch 218/300\n",
      " - 0s - loss: 0.0831 - accuracy: 0.9720 - val_loss: 1.0283 - val_accuracy: 0.7656\n",
      "Epoch 219/300\n",
      " - 0s - loss: 0.0834 - accuracy: 0.9717 - val_loss: 0.9422 - val_accuracy: 0.7891\n",
      "Epoch 220/300\n",
      " - 0s - loss: 0.0957 - accuracy: 0.9645 - val_loss: 1.1640 - val_accuracy: 0.8047\n",
      "Epoch 221/300\n",
      " - 0s - loss: 0.1215 - accuracy: 0.9488 - val_loss: 1.1632 - val_accuracy: 0.7969\n",
      "Epoch 222/300\n",
      " - 0s - loss: 0.1519 - accuracy: 0.9377 - val_loss: 1.0788 - val_accuracy: 0.7969\n",
      "Epoch 223/300\n",
      " - 0s - loss: 0.1364 - accuracy: 0.9391 - val_loss: 1.1248 - val_accuracy: 0.7344\n",
      "Epoch 224/300\n",
      " - 0s - loss: 0.0982 - accuracy: 0.9635 - val_loss: 0.9633 - val_accuracy: 0.7891\n",
      "Epoch 225/300\n",
      " - 0s - loss: 0.0878 - accuracy: 0.9710 - val_loss: 1.2634 - val_accuracy: 0.7969\n",
      "Epoch 226/300\n",
      " - 0s - loss: 0.1002 - accuracy: 0.9621 - val_loss: 1.0374 - val_accuracy: 0.7734\n",
      "Epoch 227/300\n",
      " - 0s - loss: 0.0873 - accuracy: 0.9691 - val_loss: 1.1032 - val_accuracy: 0.7734\n",
      "Epoch 228/300\n",
      " - 0s - loss: 0.0824 - accuracy: 0.9725 - val_loss: 0.8995 - val_accuracy: 0.7969\n",
      "Epoch 229/300\n",
      " - 0s - loss: 0.1003 - accuracy: 0.9616 - val_loss: 1.1802 - val_accuracy: 0.7578\n",
      "Epoch 230/300\n",
      " - 0s - loss: 0.1510 - accuracy: 0.9386 - val_loss: 0.8402 - val_accuracy: 0.7812\n",
      "Epoch 231/300\n",
      " - 0s - loss: 0.1093 - accuracy: 0.9577 - val_loss: 0.9850 - val_accuracy: 0.7734\n",
      "Epoch 232/300\n",
      " - 0s - loss: 0.0869 - accuracy: 0.9698 - val_loss: 1.1124 - val_accuracy: 0.8125\n",
      "Epoch 233/300\n",
      " - 0s - loss: 0.1007 - accuracy: 0.9664 - val_loss: 1.1817 - val_accuracy: 0.7344\n",
      "Epoch 234/300\n",
      " - 0s - loss: 0.0868 - accuracy: 0.9691 - val_loss: 1.0962 - val_accuracy: 0.7812\n",
      "Epoch 235/300\n",
      " - 0s - loss: 0.0986 - accuracy: 0.9606 - val_loss: 1.0443 - val_accuracy: 0.7812\n",
      "Epoch 236/300\n",
      " - 0s - loss: 0.0976 - accuracy: 0.9640 - val_loss: 1.3557 - val_accuracy: 0.7500\n",
      "Epoch 237/300\n",
      " - 0s - loss: 0.0801 - accuracy: 0.9717 - val_loss: 0.9577 - val_accuracy: 0.7891\n",
      "Epoch 238/300\n",
      " - 0s - loss: 0.0836 - accuracy: 0.9667 - val_loss: 1.1153 - val_accuracy: 0.7656\n",
      "Epoch 239/300\n",
      " - 0s - loss: 0.0745 - accuracy: 0.9751 - val_loss: 1.1191 - val_accuracy: 0.7812\n",
      "Epoch 240/300\n",
      " - 0s - loss: 0.0695 - accuracy: 0.9778 - val_loss: 1.2217 - val_accuracy: 0.7969\n",
      "Epoch 241/300\n",
      " - 0s - loss: 0.0666 - accuracy: 0.9778 - val_loss: 1.0581 - val_accuracy: 0.8047\n",
      "Epoch 242/300\n",
      " - 0s - loss: 0.0609 - accuracy: 0.9804 - val_loss: 1.1142 - val_accuracy: 0.8047\n",
      "Epoch 243/300\n",
      " - 0s - loss: 0.0707 - accuracy: 0.9729 - val_loss: 1.1990 - val_accuracy: 0.7969\n",
      "Epoch 244/300\n",
      " - 0s - loss: 0.0979 - accuracy: 0.9640 - val_loss: 1.0133 - val_accuracy: 0.7812\n",
      "Epoch 245/300\n",
      " - 0s - loss: 0.1136 - accuracy: 0.9548 - val_loss: 0.9946 - val_accuracy: 0.8125\n",
      "Epoch 246/300\n",
      " - 0s - loss: 0.1036 - accuracy: 0.9589 - val_loss: 1.2638 - val_accuracy: 0.7891\n",
      "Epoch 247/300\n",
      " - 0s - loss: 0.1005 - accuracy: 0.9609 - val_loss: 1.2435 - val_accuracy: 0.7734\n",
      "Epoch 248/300\n",
      " - 0s - loss: 0.1219 - accuracy: 0.9524 - val_loss: 1.0713 - val_accuracy: 0.7734\n",
      "Epoch 249/300\n",
      " - 0s - loss: 0.1155 - accuracy: 0.9531 - val_loss: 1.1406 - val_accuracy: 0.7812\n",
      "Epoch 250/300\n",
      " - 0s - loss: 0.0934 - accuracy: 0.9645 - val_loss: 1.1055 - val_accuracy: 0.8047\n",
      "Epoch 251/300\n",
      " - 0s - loss: 0.0768 - accuracy: 0.9756 - val_loss: 1.1755 - val_accuracy: 0.7734\n",
      "Epoch 252/300\n",
      " - 0s - loss: 0.0723 - accuracy: 0.9756 - val_loss: 1.1847 - val_accuracy: 0.7812\n",
      "Epoch 253/300\n",
      " - 0s - loss: 0.0804 - accuracy: 0.9725 - val_loss: 1.1552 - val_accuracy: 0.8125\n",
      "Epoch 254/300\n",
      " - 0s - loss: 0.0608 - accuracy: 0.9797 - val_loss: 1.0922 - val_accuracy: 0.8047\n",
      "Epoch 255/300\n",
      " - 0s - loss: 0.0570 - accuracy: 0.9816 - val_loss: 1.1529 - val_accuracy: 0.7734\n",
      "Epoch 256/300\n",
      " - 0s - loss: 0.0635 - accuracy: 0.9773 - val_loss: 1.1755 - val_accuracy: 0.7812\n",
      "Epoch 257/300\n",
      " - 0s - loss: 0.0773 - accuracy: 0.9693 - val_loss: 1.0036 - val_accuracy: 0.7734\n",
      "Epoch 258/300\n",
      " - 0s - loss: 0.0701 - accuracy: 0.9749 - val_loss: 1.2577 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/300\n",
      " - 0s - loss: 0.0594 - accuracy: 0.9802 - val_loss: 1.2728 - val_accuracy: 0.7812\n",
      "Epoch 260/300\n",
      " - 0s - loss: 0.0553 - accuracy: 0.9843 - val_loss: 1.1543 - val_accuracy: 0.7812\n",
      "Epoch 261/300\n",
      " - 0s - loss: 0.0673 - accuracy: 0.9763 - val_loss: 1.2658 - val_accuracy: 0.7734\n",
      "Epoch 262/300\n",
      " - 0s - loss: 0.0520 - accuracy: 0.9845 - val_loss: 1.2494 - val_accuracy: 0.7578\n",
      "Epoch 263/300\n",
      " - 0s - loss: 0.0722 - accuracy: 0.9734 - val_loss: 1.1516 - val_accuracy: 0.8047\n",
      "Epoch 264/300\n",
      " - 0s - loss: 0.0956 - accuracy: 0.9604 - val_loss: 1.2193 - val_accuracy: 0.8203\n",
      "Epoch 265/300\n",
      " - 0s - loss: 0.1337 - accuracy: 0.9468 - val_loss: 1.1559 - val_accuracy: 0.8047\n",
      "Epoch 266/300\n",
      " - 0s - loss: 0.1066 - accuracy: 0.9604 - val_loss: 1.2362 - val_accuracy: 0.8125\n",
      "Epoch 267/300\n",
      " - 0s - loss: 0.1117 - accuracy: 0.9546 - val_loss: 1.0850 - val_accuracy: 0.8047\n",
      "Epoch 268/300\n",
      " - 0s - loss: 0.0760 - accuracy: 0.9732 - val_loss: 1.2821 - val_accuracy: 0.7812\n",
      "Epoch 269/300\n",
      " - 0s - loss: 0.0669 - accuracy: 0.9758 - val_loss: 1.0528 - val_accuracy: 0.8125\n",
      "Epoch 270/300\n",
      " - 0s - loss: 0.0702 - accuracy: 0.9746 - val_loss: 1.1525 - val_accuracy: 0.7812\n",
      "Epoch 271/300\n",
      " - 0s - loss: 0.0528 - accuracy: 0.9848 - val_loss: 1.2913 - val_accuracy: 0.7500\n",
      "Epoch 272/300\n",
      " - 0s - loss: 0.0456 - accuracy: 0.9860 - val_loss: 1.1474 - val_accuracy: 0.7891\n",
      "Epoch 273/300\n",
      " - 0s - loss: 0.0467 - accuracy: 0.9841 - val_loss: 1.2693 - val_accuracy: 0.7656\n",
      "Epoch 274/300\n",
      " - 0s - loss: 0.0623 - accuracy: 0.9761 - val_loss: 1.4177 - val_accuracy: 0.7656\n",
      "Epoch 275/300\n",
      " - 0s - loss: 0.0631 - accuracy: 0.9783 - val_loss: 1.2692 - val_accuracy: 0.7578\n",
      "Epoch 276/300\n",
      " - 0s - loss: 0.0430 - accuracy: 0.9891 - val_loss: 1.3848 - val_accuracy: 0.7500\n",
      "Epoch 277/300\n",
      " - 0s - loss: 0.0459 - accuracy: 0.9872 - val_loss: 1.2434 - val_accuracy: 0.7891\n",
      "Epoch 278/300\n",
      " - 0s - loss: 0.0336 - accuracy: 0.9928 - val_loss: 1.3154 - val_accuracy: 0.7891\n",
      "Epoch 279/300\n",
      " - 0s - loss: 0.0357 - accuracy: 0.9911 - val_loss: 1.3328 - val_accuracy: 0.7812\n",
      "Epoch 280/300\n",
      " - 0s - loss: 0.0353 - accuracy: 0.9925 - val_loss: 1.3809 - val_accuracy: 0.7891\n",
      "Epoch 281/300\n",
      " - 0s - loss: 0.0352 - accuracy: 0.9911 - val_loss: 1.3077 - val_accuracy: 0.7656\n",
      "Epoch 282/300\n",
      " - 0s - loss: 0.0539 - accuracy: 0.9799 - val_loss: 1.2781 - val_accuracy: 0.7734\n",
      "Epoch 283/300\n",
      " - 0s - loss: 0.0720 - accuracy: 0.9746 - val_loss: 1.4229 - val_accuracy: 0.7734\n",
      "Epoch 284/300\n",
      " - 0s - loss: 0.0787 - accuracy: 0.9712 - val_loss: 1.2396 - val_accuracy: 0.7734\n",
      "Epoch 285/300\n",
      " - 0s - loss: 0.0857 - accuracy: 0.9693 - val_loss: 1.4702 - val_accuracy: 0.7344\n",
      "Epoch 286/300\n",
      " - 0s - loss: 0.0954 - accuracy: 0.9652 - val_loss: 1.4093 - val_accuracy: 0.7891\n",
      "Epoch 287/300\n",
      " - 0s - loss: 0.1725 - accuracy: 0.9369 - val_loss: 1.4230 - val_accuracy: 0.7422\n",
      "Epoch 288/300\n",
      " - 0s - loss: 0.1290 - accuracy: 0.9490 - val_loss: 1.3098 - val_accuracy: 0.7969\n",
      "Epoch 289/300\n",
      " - 0s - loss: 0.1470 - accuracy: 0.9386 - val_loss: 1.2282 - val_accuracy: 0.7891\n",
      "Epoch 290/300\n",
      " - 0s - loss: 0.0636 - accuracy: 0.9768 - val_loss: 1.2148 - val_accuracy: 0.8203\n",
      "Epoch 291/300\n",
      " - 0s - loss: 0.0367 - accuracy: 0.9913 - val_loss: 1.3827 - val_accuracy: 0.8125\n",
      "Epoch 292/300\n",
      " - 0s - loss: 0.0395 - accuracy: 0.9894 - val_loss: 1.3426 - val_accuracy: 0.8125\n",
      "Epoch 293/300\n",
      " - 0s - loss: 0.0408 - accuracy: 0.9870 - val_loss: 1.4160 - val_accuracy: 0.8047\n",
      "Epoch 294/300\n",
      " - 0s - loss: 0.0335 - accuracy: 0.9920 - val_loss: 1.3219 - val_accuracy: 0.7969\n",
      "Epoch 295/300\n",
      " - 0s - loss: 0.0286 - accuracy: 0.9947 - val_loss: 1.3061 - val_accuracy: 0.7969\n",
      "Epoch 296/300\n",
      " - 0s - loss: 0.0337 - accuracy: 0.9915 - val_loss: 1.4882 - val_accuracy: 0.7656\n",
      "Epoch 297/300\n",
      " - 0s - loss: 0.0349 - accuracy: 0.9911 - val_loss: 1.3493 - val_accuracy: 0.8047\n",
      "Epoch 298/300\n",
      " - 0s - loss: 0.0317 - accuracy: 0.9911 - val_loss: 1.4143 - val_accuracy: 0.7734\n",
      "Epoch 299/300\n",
      " - 0s - loss: 0.0481 - accuracy: 0.9843 - val_loss: 1.2847 - val_accuracy: 0.8125\n",
      "Epoch 300/300\n",
      " - 0s - loss: 0.0566 - accuracy: 0.9812 - val_loss: 1.4258 - val_accuracy: 0.8125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x159270750>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Network time\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train,validation_data=(X_test,y_test), epochs=300, batch_size=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)\n",
    "preds = [i > .50 for i in preds]\n",
    "predicted = []\n",
    "for pred in preds:\n",
    "    val = pred[0]\n",
    "    predicted.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.78      0.80        63\n",
      "        True       0.80      0.85      0.82        65\n",
      "\n",
      "    accuracy                           0.81       128\n",
      "   macro avg       0.81      0.81      0.81       128\n",
      "weighted avg       0.81      0.81      0.81       128\n",
      "\n",
      "[[49 14]\n",
      " [10 55]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,predicted))\n",
    "print(confusion_matrix(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
